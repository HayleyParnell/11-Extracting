{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fcb8068-f1b8-4db1-9a5c-089ee2202e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "# Ignore specific warnings\n",
    "warnings.filterwarnings('ignore')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "915263ef-0d25-4f26-957b-c3435f6960d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variable for OpenMP threads\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dd2f9fb-51d6-4cad-a8ce-85ae2bfdbee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the Excel files\n",
    "excel_dir = r'C:\\Users\\hparnell\\Desktop\\MH10010\\Resources'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb181f18-68d8-4d95-85d0-8263be06bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all Excel files into a list of data frames\n",
    "data_frames = []\n",
    "file_names = []\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db426b75-29af-4a01-b3cb-3ed560f711ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(excel_dir):\n",
    "    if file.endswith('.xlsx') or file.endswith('.xls'):\n",
    "        df = pd.read_excel(os.path.join(excel_dir, file))\n",
    "        data_frames.append(df)\n",
    "        file_names.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874a648e-ee05-4a2f-8758-2c9361052479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrames to text data for clustering\n",
    "text_data = []\n",
    "for df in data_frames:\n",
    "    # Convert each column to string type individually to avoid NULLs due to type mismatches\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].astype(str, errors='ignore')\n",
    "\n",
    "    #Flatten the DataFrame\n",
    "    text = df.astype(str).values.flatten()\n",
    "    text = ' '.join(text)\n",
    "    text_data.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece45de-0643-4db3-b813-1cd531bfec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(text_data)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f98593d-8803-4918-978c-e0194a25a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37df52-5802-4c8d-8ff6-a8249caa9748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-means clustering on the similarity matrix\n",
    "num_clusters = 10  # Adjust based on your needs\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac97b2b3-c588-4794-9825-6da31019660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster labels\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee53e2e1-6106-4c85-87a6-f40d48ed2bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the subsets\n",
    "subsets = {i: [] for i in range(num_clusters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce4c67-b289-44d6-ae95-40e25d7be890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign files to clusters\n",
    "for i, label in enumerate(labels):\n",
    "    subsets[label].append(file_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e41b39-096b-49c0-97bb-5ef5448532c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each cluster's filenames to a CSV file\n",
    "output_dir = r'C:\\Users\\hparnell\\Desktop\\MH10010\\Clustered_Files'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f05421b-723c-4e3f-b02d-f75bd62d17cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster, files in subsets.items():\n",
    "    df = pd.DataFrame(files, columns=[\"File Name\"])\n",
    "    file_path = os.path.join(output_dir, f'cluster_{cluster}_files.csv')\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Cluster {cluster} DataFrame saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa081ee3-97c3-4f57-8930-25cf0f52e0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ExcelProcessing\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.crealytics:spark-excel_2.12:0.13.5\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab870a24-266a-4c76-8ca1-0b11539a9282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_string_schema(columns):\n",
    "    return StructType([StructField(column, StringType(), True) for column in columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca857818-cf8b-45df-ad5f-8aa1f14abe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_to_dataframe(file_path, schema):\n",
    "    try:\n",
    "        df = spark.read.format('com.crealytics.spark.excel') \\\n",
    "                       .option('dataAddress', \"'Sheet1'!A1\") \\\n",
    "                       .option('header', 'true') \\\n",
    "                       .option('inferSchema', 'false') \\\n",
    "                       .schema(schema) \\\n",
    "                       .load(file_path)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682076d5-e9c9-48b0-af5a-d9bb01c01095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for each cluster\n",
    "dataframes = {i: [] for i in range(num_clusters)}\n",
    "for cluster_id, files in subsets.items():\n",
    "    if files:\n",
    "        # Use the first file to infer the schema\n",
    "        sample_df = pd.read_excel(os.path.join(excel_dir, files[0]), nrows=0)\n",
    "        schema = get_string_schema(sample_df.columns)\n",
    "        for file in files:\n",
    "            file_path = os.path.join(excel_dir, file)\n",
    "            df = load_data_to_dataframe(file_path, schema)\n",
    "            if df:\n",
    "                dataframes[cluster_id].append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8720b7c7-896a-4750-b654-bf4ead2e96bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all DataFrames into one for each cluster\n",
    "combined_dfs = {}\n",
    "for cluster_id, dfs in dataframes.items():\n",
    "    if dfs:\n",
    "        combined_df = dfs[0]\n",
    "        for df in dfs[1:]:\n",
    "            combined_df = combined_df.union(df)\n",
    "        combined_dfs[cluster_id] = combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9152f4c-ad58-434c-8659-afbc93ff3ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show combined DataFrames for each cluster\n",
    "for cluster_id, df in combined_dfs.items():\n",
    "    print(f\"Cluster {cluster_id} Combined DataFrame:\")\n",
    "    df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
