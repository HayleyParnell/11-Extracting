{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db1472f-fecd-46cb-ab59-4604ed425732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ExcelProcessing\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.crealytics:spark-excel_2.12:0.13.5\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a0002d-a2b6-4140-a447-3835e12a8765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6904fe-4b31-4f78-986a-c1fbe8bb5926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_string_schema(columns):\n",
    "    return StructType([StructField(column, StringType(), True) for column in columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046264d4-9aa5-43fd-a6b2-f9cdb6182a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_to_dataframe(file_path, schema):\n",
    "    try:\n",
    "        df = spark.read.format('com.crealytics.spark.excel') \\\n",
    "                       .option('dataAddress', \"'Sheet1'!A1\") \\\n",
    "                       .option('header', 'true') \\\n",
    "                       .option('inferSchema', 'false') \\\n",
    "                       .schema(schema) \\\n",
    "                       .load(file_path)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56200829-52bc-4914-8e4f-82ffd3bc0a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for each cluster\n",
    "dataframes = {i: [] for i in range(num_clusters)}\n",
    "for cluster_id, files in subsets.items():\n",
    "    if files:\n",
    "        # Use the first file to infer the schema\n",
    "        sample_df = pd.read_excel(os.path.join(excel_dir, files[0]), nrows=0)\n",
    "        schema = get_string_schema(sample_df.columns)\n",
    "        for file in files:\n",
    "            file_path = os.path.join(excel_dir, file)\n",
    "            df = load_data_to_dataframe(file_path, schema)\n",
    "            if df:\n",
    "                dataframes[cluster_id].append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3aea55-8f3f-4095-aa94-a53b46fdb120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all DataFrames into one for each cluster\n",
    "combined_dfs = {}\n",
    "for cluster_id, dfs in dataframes.items():\n",
    "    if dfs:\n",
    "        combined_df = dfs[0]\n",
    "        for df in dfs[1:]:\n",
    "            combined_df = combined_df.union(df)\n",
    "        combined_dfs[cluster_id] = combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79795eef-76b6-4e4b-b426-fcf73f122af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show combined DataFrames for each cluster\n",
    "for cluster_id, df in combined_dfs.items():\n",
    "    print(f\"Cluster {cluster_id} Combined DataFrame:\")\n",
    "    df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
